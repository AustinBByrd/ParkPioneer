"""first

Revision ID: 587b4e5059ca
Revises: 
Create Date: 2024-01-31 10:13:21.460077

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '587b4e5059ca'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
   pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('password', sa.VARCHAR(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('admin_status', sa.BOOLEAN(), autoincrement=False, nullable=True))
        batch_op.drop_constraint(None, type_='unique')
        batch_op.drop_constraint(None, type_='unique')
        batch_op.alter_column('created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('username',
               existing_type=sa.VARCHAR(),
               nullable=True)
        batch_op.alter_column('email',
               existing_type=sa.VARCHAR(),
               nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)
        batch_op.drop_column('_password_hash')

    with op.batch_alter_table('user_events', schema=None) as batch_op:
        batch_op.add_column(sa.Column('id', sa.BIGINT(), sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1), autoincrement=True, nullable=False))
        batch_op.drop_constraint(batch_op.f('fk_user_events_user_id_users'), type_='foreignkey')
        batch_op.create_foreign_key('user_events_id_fkey', 'users', ['id'], ['id'])
        batch_op.alter_column('event_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False)
        batch_op.drop_column('user_id')

    with op.batch_alter_table('parks', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('houses', schema=None) as batch_op:
        batch_op.alter_column('user_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('favorite_parks', schema=None) as batch_op:
        batch_op.alter_column('park_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=True)
        batch_op.alter_column('user_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               nullable=True,
               autoincrement=True)

    with op.batch_alter_table('events', schema=None) as batch_op:
        batch_op.create_foreign_key('events_id_fkey', 'users', ['id'], ['id'])
        batch_op.alter_column('park_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)

    op.create_table('user_activity_log',
    sa.Column('id', sa.BIGINT(), sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1), autoincrement=True, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('timestamp', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['id'], ['users.id'], name='user_activity_log_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='user_activity_log_pkey')
    )
    op.drop_table('user_activity_logs')
    # ### end Alembic commands ###
